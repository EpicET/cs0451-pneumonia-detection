import torch

class Transformer():
    
    def __init__(self, input_dim, output_dim, num_heads, num_layers):
        super(Transformer, self).__init__()
        
        # Positional Encoding
        
        
        # Encoding Layers
        
        ## Multi-Head Attention
        
        ## Normalization
        
        ## Feed Forward Network
        
        # Decoding Layers
        
        
        
    def forward(self, x):
        pass
        
  
    
    