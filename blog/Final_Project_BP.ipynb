{
 "cells": [
  {
   "cell_type": "raw",
   "id": "2cded8aa",
   "metadata": {},
   "source": [
    "---\n",
    "title: Pnuemonia Detection\n",
    "author: Lia Smith, Cameron Hudson, Robsan Dinka, Emmanuel Towner \n",
    "date: '2025-05-19'\n",
    "image: 'image.png'\n",
    "description: In this project, we built a convolutional neural network to embed chest X-ray images into a latent space, then compared three binary classifiers—Support Vector Machine, XGBoost, and Transformer—on their ability to detect pneumonia. Using contrastive learning and a variational autoencoder, we trained models on the Pneumonia Chest X-ray dataset from Kaggle. All models achieved around 78% accuracy, with high precision (up to 93%) but lower recall (as low as 37%). Our results highlight both the potential and limitations of non-CNN classifiers in medical image classification, particularly in contexts where false negatives carry high risk.\n",
    "format: html\n",
    "bibliography: refs.bib\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdfc586",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "\n",
    "Within our blog post, we created a neural network and implemented three different binary classifiers trained on chest x-ray image data to detect pneumonia based on images. We used convolution layers to convert images into latent vectors by which we could feed into our various machine learning models: a transformer, an SVM, and a gradient boosting model. Through analyzing the accuracy of each model, we discovered a similar accuracy between the models of around 78% on testing data.\n",
    "\n",
    "[Here is the link our code.](https://github.com/EpicET/cs0451-pneumonia-detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f8ba09",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Within our project, we wanted to compare 3 seperate binary classification machine learning models, seeing which is best for an image classification task. Our project attempts to uncover what types of algorithms are best for binary image classification tasks using the pneumonia chest xray dataset, with our models being trained to discern pneumonia based on chest xray images only. This dataset demonstrates a case where finding the most optimal image classifcation algorithm is very important as it could result in saving a life. Our research could also inform which types of algorithms should be considered other important image classification tasks. We found five studies the explored other work done by scholars.\n",
    "\n",
    "In the study by @mobileNet2023, the researchers mainly focus on deep learning algorithms to tackle this same image classification task. Through their research, they discovered the MobileNet CCN gave the best accuracy on two datasets with values of 94.23% and 93.75%. In another study titled @chexnet2017, researchers create their own CNN known as CheXNet that detects pneumonia as well as other chest related illnesses (fibrosis, hernia, etc.) that which accuracies ranging from 0.7 to 0.9. With such a large focus on CNNs for this image classification, we wanted to determine if other kinds of algorithms good for binary classification could also be useful image classifiers.\n",
    "\n",
    "Recent research has expanded the exploration of deep learning architectures for pneumonia detection. For instance, a study by @singh2021pneumonia compared a custom convolutional neural network (CNN) and a multilayer perceptron (MLP) for classifying chest X-ray images. The CNN achieved an accuracy of 92.63%, outperforming the MLP's 77.56%, highlighting the efficacy of CNNs in medical image classification tasks. Furthermore, a study by @mabrouk2023ensemble proposed an ensemble learning approach combining DenseNet169, MobileNetV2, and Vision Transformer models for pneumonia detection in chest X-ray images. Their ensemble model achieved an accuracy of 93.91% and an F1-score of 93.88%, indicating that integrating multiple deep learning architectures can improve classification performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c76e21",
   "metadata": {},
   "source": [
    "## Values Statement\n",
    "The potential users of our project would be primary care clinicians and radiologists who must regularly discern chest-related illnesses through X-rays. These machine learning models trained on chest X-ray image data may help them make more informed decisions if they are trying to discern specifically pneumonia.\n",
    "\n",
    "We believe that our work contributes to AI researchers who are studying how to optimize for performance in image classification tasks, especially regarding medical concerns. If it can inform medical researchers on what machine learning models are best at medical image classification, they and their patients can also benefit from greater accuracy in detecting chest-related illnesses.\n",
    "\n",
    "Because our models are quite poor at predicting images without pneumonia correctly, they could falsely flag patients as having pneumonia, which may lead them to incur unnecessary medical expenses. Based on the background of these patients, this could seriously affect patients who struggle financially.\n",
    "\n",
    "Our group personally enjoyed and had an interest in each of the algorithms that we worked on and took this project as a learning experience to expand our knowledge on what image vectorization and binary classification algorithms are out there and how they differ from what we have learned through our class assignments.\n",
    "\n",
    "Based on our experiments, we believe if our project can help inform image classification tasks, especially those in the medical field, then the world can become a better place by being able to help people detect illnesses earlier and possibly save lives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d0d0ae",
   "metadata": {},
   "source": [
    "## Materials\n",
    "Our data comes from the Pneumonia Chest X-ray dataset on Kaggle. This data came from the Guangzhou Women and Children’s Medical Center. Samples were collected from patients and labels were created by pneumonia specialists, with two specialists making labels and then a third corroborating the label of normal or pneumonia. Our data lacks information regarding the severity or time span of the pneumonia for positive cases, meaning that the model has no clear way of understanding which X-rays should be encoded closer or further away from the normal cases. Additionally, the dataset has a 64% / 36% split, with the majority of X-rays containing positive cases of pneumonia. This bias happens to work out well for mitigating false negatives; however, it makes models have more difficulty understanding when an X-ray is normal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467ff1d6",
   "metadata": {},
   "source": [
    "## Results \n",
    "<img width=\"262\" alt=\"image\" src=\"https://github.com/user-attachments/assets/2bd2c6ef-4d1a-4994-ad37-e454924eee0d\" />\n",
    "<img width=\"463\" alt=\"image\" src=\"https://github.com/user-attachments/assets/897d1e6c-110d-4291-bec7-f3ea6cc16fc5\" />\n",
    "\n",
    "As demonstrated before, the models contained much higher precision rates than recall in order to catch more of the positive pneumonia cases due to their costliness as compared to the costs associated with missing a normal case. Within the models, the transformer did the best, with the highest recall and precision of 93% and 41% respectively. The F-1 score of 57% suggests that the model was beginning to learn differences between the classes but still encountered much difficulty. This is also present in the 3-D PCA plot of the latent vectors where it becomes evident that many of the embeddings are caught in an overlapping region where both classes meet. The results suggest that the image embeddings need more fine-tuning to increase accuracy and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27dbed7e",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "The project accomplished many of the goals that we set out to accomplish during the duration of this project and also failed to meet others. We got a working convolutional neural network to embed the images and learn important features of those images. We correctly identify 93% of all pneumonia cases. On the other hand, we correctly identify less than half of all normal cases. This project demonstrates the difficulty of complex machine learning tasks without good computational resources. Running and auditing the CNN alone takes two hours per run with a GPU. Due to this constraint, we were unable to readily take advantage of all of the data available. Additionally, the binary classification models also took 5–15 minutes depending on the model. The most apparent hurdle in this project was creating a complex model while also being able to run it in a reasonable amount of time. Other pneumonia binary classification projects are able to get higher accuracy through the usage of pre-made ResNet models. These models are trained on millions of images and use residual connections to improve the performance of neural networks. If we had more time, we would do a more thorough error analysis of misclassified normal images to understand what features the model is missing and improve the architecture to capture that feature. Additionally, we would utilize more of the training data without run-time constraints and try adopting residual neural network architecture to improve performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb94b7e",
   "metadata": {},
   "source": [
    "## Group Contributions:\n",
    "\n",
    "Lia did the data preprocessing for the images and all visualizations such as the PCA plot. Furthermore, she made the both  autoencoders, latent vectors, and worked on evaluation metrics for the models. For the blog posts she did the material and methods, results, and conclusions. Cameron worked on XGBoost Model in the project and wrote the introduction, abstract, and values statement of the blog post. Robsan worked on the Support Vector Machine. Emmanuel created the transformer and worked on model evaluation. Broadly adapted code imported from Google colab to be functional on the notebook. For the blog post, he added to the introduction and make did the reference implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba35d0a7",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "::: {#refs}\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48833fc4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-0451",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
