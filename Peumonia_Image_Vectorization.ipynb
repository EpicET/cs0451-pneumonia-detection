{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import kagglehub\n",
    "\n",
    "# Download chest x-ray (will take a minute or two)\n",
    "data_path = kagglehub.dataset_download(\"paultimothymooney/chest-xray-pneumonia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Data downloaded to {data_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = data_path + \"/chest_xray/train\"\n",
    "test_path = data_path + \"/chest_xray/test\"\n",
    "val_path = data_path + \"/chest_xray/test\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "331654a6",
    "outputId": "38b0ed3d-aa77-4638-f1ab-134e4db06634"
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(), #compression 3 rgb matrix into one for runtime\n",
    "    transforms.Resize((224, 224)), # can downsample here for runtime\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "#Loading train, test, and validation datasets.\n",
    "train_dataset = datasets.ImageFolder(train_path, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(test_path, transform=transform)\n",
    "val_dataset = datasets.ImageFolder(val_path, transform = transform)\n",
    "\n",
    "#dataloaders w 32 images each for batches (randomized)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(train_dataset.classes) # classes for the data (train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### Test Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 839
    },
    "id": "b4cf45a4",
    "outputId": "412a7965-1b3c-4bd8-8398-a6fc7831eb15"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#image batch\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter) #image, label pair\n",
    "\n",
    "\n",
    "img_ten = images[0] #getting the 0th image/label pair\n",
    "label = labels[0]\n",
    "\n",
    "#tensor to NumPy (tensors no work for plotting :P)\n",
    "img_np = img_ten.numpy()\n",
    "img_np = np.transpose(img_np, (1, 2, 0))  #NOTE that the height/width need to be reordered when converting\n",
    "\n",
    "#Image plot with the label on the top (thanks Chodrow!!!)\n",
    "plt.imshow(img_np, cmap='gray')\n",
    "plt.title(f\"Label: {train_dataset.classes[label]}\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "i=10\n",
    "pnu_img_ten = images[i]\n",
    "\n",
    "pnu_label = labels[i]\n",
    "\n",
    "pnu_img_np = pnu_img_ten.numpy()\n",
    "pnu_img_np = np.transpose(pnu_img_np, (1, 2, 0))\n",
    "\n",
    "plt.imshow(pnu_img_np, cmap='gray')\n",
    "plt.title(f\"Label: {train_dataset.classes[pnu_label]}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "41b5c012",
    "outputId": "8b5fbb95-dd01-4e5a-dee1-f13f40fa9b52"
   },
   "outputs": [],
   "source": [
    "#Image Dimension (for later)\n",
    "pnu_img_ten.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Pneumonia Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "id": "5a9f3f48"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from PneumoniaAutoencoder import PneumoniaAutoencoder\n",
    "\n",
    "# Instantiate encoder, loss, optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") #easy to switch between cpu and gpu\n",
    "autoencoder = PneumoniaAutoencoder().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### Autoencoder training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "id": "6eaf897c"
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(autoencoder.parameters(), lr=1e-3)\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    autoencoder.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # progress bar (really nice)\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "\n",
    "    for images, _ in pbar:\n",
    "        images = images.to(device)\n",
    "\n",
    "        outputs = autoencoder(images)\n",
    "        loss = criterion(outputs, images)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Update bar\n",
    "        pbar.set_postfix({'loss': loss.item()})\n",
    "\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Avg Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "id": "30ca87fa",
    "outputId": "2e58bb7b-8946-4f25-99b9-9e6cf968f359"
   },
   "outputs": [],
   "source": [
    "## reconstructed images\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# eval\n",
    "autoencoder.eval()\n",
    "\n",
    "# batch\n",
    "dataiter = iter(train_loader)\n",
    "images, _ = next(dataiter)\n",
    "images = images.to(device)\n",
    "\n",
    "# Reconstruct images\n",
    "with torch.no_grad():\n",
    "    reconstructions = autoencoder(images)\n",
    "\n",
    "# Move tensors to CPU for plotting (np can't use gpu)\n",
    "images = images.cpu()\n",
    "reconstructions = reconstructions.cpu()\n",
    "\n",
    "#transpose for tensor --> numpy\n",
    "def tensor_to_img(t):\n",
    "    t = t.numpy()\n",
    "    t = np.transpose(t, (1, 2, 0))\n",
    "    return t\n",
    "\n",
    "# Plot original and reconstructed\n",
    "n = 6 #num images\n",
    "plt.figure(figsize=(12, 4))\n",
    "for i in range(n):\n",
    "    # Original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(tensor_to_img(images[i]))\n",
    "    ax.set_title(\"Original\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # Reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(tensor_to_img(reconstructions[i]))\n",
    "    ax.set_title(\"Reconstructed\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {
    "id": "Kgu3lNNhf7zY"
   },
   "source": [
    "### Autoencoder PCA plot \n",
    "This to check if differences encoded are meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "id": "7EKgKYMRgAfI"
   },
   "outputs": [],
   "source": [
    "autoencoder.eval()\n",
    "latent_vectors = []\n",
    "labels_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_loader:  # labels: 0=norm, 1=pneu\n",
    "        images = images.to(device)\n",
    "        encoded = autoencoder.encoder(images)\n",
    "        # Flatten\n",
    "        encoded = encoded.view(encoded.size(0), -1).cpu().numpy()\n",
    "        latent_vectors.append(encoded)\n",
    "        labels_list.append(labels.cpu().numpy())\n",
    "\n",
    "# Stack into arrays\n",
    "import numpy as np\n",
    "X = np.vstack(latent_vectors)\n",
    "y = np.hstack(labels_list)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2) #2 Principal components\n",
    "X_pca = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "NQf4jg74gbf5",
    "outputId": "ab82f484-83f1-4b01-c222-cc2b9d992605"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_pca[y==0, 0], X_pca[y==0, 1], label=\"Normal\", alpha=0.5)\n",
    "plt.scatter(X_pca[y==1, 0], X_pca[y==1, 1], label=\"Pneumonia\", alpha=0.5)\n",
    "plt.title(\"PCA of Autoencoder Latent Space\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {
    "id": "24107b28"
   },
   "source": [
    "## Variational AutoEncoder with Contrastive loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contrastive loss function for VAE\n",
    "def supervised_contrastive_loss(embeddings, labels: torch.Tensor, temperature=0.1):\n",
    "    device = embeddings.device\n",
    "    labels = labels.contiguous().view(-1, 1)\n",
    "    mask = torch.eq(labels, labels.T).float().to(device)\n",
    "\n",
    "    dot_product = (embeddings @ embeddings.T) / temperature\n",
    "    logits_max, _ = torch.max(dot_product, dim=1, keepdim=True)\n",
    "    logits = dot_product - logits_max.detach()\n",
    "\n",
    "    exp_logits = torch.exp(logits) * (1 - torch.eye(len(labels), device=device))\n",
    "    log_prob = logits - torch.log(exp_logits.sum(1, keepdim=True) + 1e-8)\n",
    "\n",
    "    mean_log_prob_pos = (mask * log_prob).sum(1) / mask.sum(1)\n",
    "    loss = -mean_log_prob_pos.mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_balanced_indices(labels):\n",
    "    \"\"\"Returns an equal number of positive and negative indices.\"\"\"\n",
    "    pos_indices = [i for i, y in enumerate(labels) if y == 1]\n",
    "    neg_indices = [i for i, y in enumerate(labels) if y == 0]\n",
    "\n",
    "    min_class_len = min(len(pos_indices), len(neg_indices))\n",
    "    pos_sample = np.random.choice(pos_indices, min_class_len, replace=False)\n",
    "    neg_sample = np.random.choice(neg_indices, min_class_len, replace=False)\n",
    "\n",
    "    return np.concatenate([pos_sample, neg_sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "id": "wN0t56_MmDA2"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from ContrastiveVAE import ContrastiveVAE\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def train_vae(model_class, dataset, optimizer_class, device, epochs=10, beta=1.0, contrastive_weight=1.0):\n",
    "    recon_loss_fn = nn.MSELoss(reduction='sum')\n",
    "    k_folds = 5\n",
    "    batch_size = 32\n",
    "    kf = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "    all_labels = [label for _, label in dataset]\n",
    "    fold_results = []\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(dataset)):\n",
    "        print(f\"\\nFold {fold + 1}\")\n",
    "        print(\"-------\")\n",
    "\n",
    "        #Balanced sampling\n",
    "        train_labels = [all_labels[i] for i in train_idx]\n",
    "        balanced_indices = get_balanced_indices(train_labels)\n",
    "        balanced_train_idx = [train_idx[i] for i in balanced_indices]\n",
    "\n",
    "        #Loaders\n",
    "        train_loader = DataLoader(\n",
    "            dataset,\n",
    "            batch_size=batch_size,\n",
    "            sampler=SubsetRandomSampler(balanced_train_idx),\n",
    "        )\n",
    "        test_loader = DataLoader(\n",
    "            dataset,\n",
    "            batch_size=batch_size,\n",
    "            sampler=SubsetRandomSampler(test_idx),\n",
    "        )\n",
    "\n",
    "        #model and optimizer\n",
    "        VAE = model_class().to(device)\n",
    "        optimizer = optimizer_class(VAE.parameters())\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            VAE.train()\n",
    "            total_loss = 0\n",
    "\n",
    "            for x, y in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                x_recon, mu, logvar = VAE(x)\n",
    "                recon_loss = recon_loss_fn(x_recon, x) / x.size(0)\n",
    "                kl_loss = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "                contrastive = supervised_contrastive_loss(mu, y)\n",
    "\n",
    "                loss = recon_loss + beta * kl_loss + contrastive_weight * contrastive\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            print(f\"Epoch {epoch+1} - Train Loss: {total_loss / len(train_loader):.4f}\")\n",
    "\n",
    "        #test set evaluation\n",
    "        VAE.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in test_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                x_recon, mu, logvar = VAE(x)\n",
    "                recon_loss = recon_loss_fn(x_recon, x) / x.size(0)\n",
    "                kl_loss = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "                contrastive = supervised_contrastive_loss(mu, y)\n",
    "                loss = recon_loss + beta * kl_loss + contrastive_weight * contrastive\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(test_loader)\n",
    "        print(f\"Fold {fold + 1} - Validation Loss: {val_loss:.4f}\")\n",
    "        fold_results.append(val_loss)\n",
    "\n",
    "    print(f\"\\nAverage Validation Loss: {np.mean(fold_results):.4f} Â± {np.std(fold_results):.4f}\")\n",
    "    return VAE #returning trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### Training ConstrastiveVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZPDhBdu_npUm",
    "outputId": "ca573de4-a8e7-4a65-c3e2-bed4ded30c98"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "cont_encoder = train_vae(\n",
    "    model_class=lambda: ContrastiveVAE(latent_dim=64),\n",
    "    dataset=train_dataset,\n",
    "    optimizer_class=lambda params: torch.optim.Adam(params, lr=1e-3),\n",
    "    device=device,\n",
    "    epochs=1,\n",
    "    beta=1.0,\n",
    "    contrastive_weight=5.0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "id": "dwJO6Zugx3xD"
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "def plot_latent_space_3d(model, dataloader, device):\n",
    "    model.eval()\n",
    "    mus = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x = x.to(device)\n",
    "            x_recon, mu, logvar = model(x)\n",
    "            mus.append(mu.cpu().numpy())\n",
    "            labels.append(y.numpy())\n",
    "\n",
    "    mus = np.concatenate(mus, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "\n",
    "    # PCA\n",
    "    pca = PCA(n_components=3)\n",
    "    reduced = pca.fit_transform(mus)\n",
    "\n",
    "    # pd.data.frame for plotly!\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame({\n",
    "        'PC1': reduced[:, 0],\n",
    "        'PC2': reduced[:, 1],\n",
    "        'PC3': reduced[:, 2],\n",
    "        'Label': labels\n",
    "    })\n",
    "\n",
    "    fig = px.scatter_3d(df, x='PC1', y='PC2', z='PC3',\n",
    "                        color=df['Label'].astype(str),\n",
    "                        title='3D PCA of Latent Space',\n",
    "                        labels={'color': 'Class'},\n",
    "                        opacity=0.7)\n",
    "    fig.update_traces(marker=dict(size=4))\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "ftBBzBFtnwFC",
    "outputId": "d417e270-0958-4c60-8e91-82f53a3cfae0"
   },
   "outputs": [],
   "source": [
    "plot_latent_space_3d(cont_encoder, train_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {
    "id": "5NxGpe-B0JVU"
   },
   "source": [
    "## Training and Classification with Muliple Modeles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "### Train, Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {
    "id": "GPr0eXZG0EEQ"
   },
   "outputs": [],
   "source": [
    "def extract_latent_vectors(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_mu = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x = x.to(device)\n",
    "            mu, _ = model.encode(x)\n",
    "            all_mu.append(mu.cpu().numpy()) #add all into np array\n",
    "            all_labels.append(y.numpy())\n",
    "\n",
    "    X = np.concatenate(all_mu, axis=0)\n",
    "    y = np.concatenate(all_labels, axis=0)\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, y_train = extract_latent_vectors(cont_encoder, train_loader, device)\n",
    "X_test, y_test = extract_latent_vectors(cont_encoder, test_loader, device)\n",
    "# X_train.shape is (5216, 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1beGZ0CQ0SH1",
    "outputId": "4adfbdd2-4433-426b-9bf3-b8fae6718b9e"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "LR = LogisticRegression(max_iter=100, verbose = 1)\n",
    "LR.fit(X_train, y_train)\n",
    "\n",
    "y_pred = LR.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "# print(classification_report(y_test, y_pred, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "NhxPfS8K0Wjz",
    "outputId": "4328e0a4-458a-4dbf-fdc4-1224d3f7f93c"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(LR, X_test, y_test)\n",
    "plt.title(\"Confusion Matrix for Logistic Regression\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Transformer import Transformer\n",
    "\n",
    "# latent_vectors = X_train.shape[0] # 5216 latent vectors\n",
    "latent_dim = X_train.shape[1] # 64 dimensions of latent space\n",
    "output_dim = 2\n",
    "\n",
    "# Initialize the Transformer model\n",
    "T = Transformer(input_dim = latent_dim, num_patches = 1, output_dim=output_dim, hidden_dim=latent_dim).to(device)\n",
    "\n",
    "# Train the Transformer model\n",
    "def train_transformer(model: Transformer, X_train, y_train, device, epochs=3, batch_size=32):\n",
    "    X = torch.tensor(X_train, dtype=torch.float32).to(device)  # [vectors, dim]\n",
    "    y = torch.tensor(y_train, dtype=torch.long).to(device)  # [labels]\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        i = 0\n",
    "        # Simulates batch loading method without dataloader\n",
    "        while i < X.shape[0]: # Simulates batch loading method without dataloader\n",
    "            # Create batches\n",
    "            x_batch = X[i:i + batch_size]\n",
    "            y_batch = y[i:i + batch_size]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x_batch)  \n",
    "            loss = criterion(outputs, y_batch)  \n",
    "            loss.backward()  \n",
    "            optimizer.step()  \n",
    "\n",
    "            total_loss += loss.item()\n",
    "            i += batch_size  \n",
    "\n",
    "        print(f\"Epoch {epoch + 1} - Loss: {total_loss / (X.shape[0] // batch_size):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "train_transformer(T, X_train, y_train, device, epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loop\n",
    "def test_transformer(model: Transformer, X_test, y_test, device, batch_size=32):\n",
    "    X = torch.tensor(X_test, dtype=torch.float32).to(device)  # [vectors, dim]\n",
    "    y = torch.tensor(y_test, dtype=torch.long).to(device)  # [labels]\n",
    "    X, y = X.to(device), y.to(device)\n",
    "    \n",
    "    y_preds = []\n",
    "    y_trues = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        i = 0\n",
    "        while i < X.shape[0]: \n",
    "            # Create batches\n",
    "            x_batch = X[i:i + batch_size]\n",
    "            y_batch = y[i:i + batch_size]\n",
    "\n",
    "            outputs = model(x_batch)  # (batch_size, num_classes)\n",
    "            preds = outputs.argmax(dim=1)  # Predicted labels\n",
    "\n",
    "            y_preds.append(preds)\n",
    "            y_trues.append(y_batch)\n",
    "\n",
    "            i += batch_size\n",
    "            \n",
    "    # 2. Concatenate all batches\n",
    "    y_preds = torch.cat(y_preds).cpu().numpy()\n",
    "    y_trues = torch.cat(y_trues).cpu().numpy()\n",
    "\n",
    "    # 3. Calculate accuracy and classification report\n",
    "    acc = accuracy_score(y_trues, y_preds)\n",
    "    cm = confusion_matrix(y_trues, y_preds)\n",
    "    print(classification_report(y_trues, y_preds))\n",
    "    \n",
    "    return acc, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, cm = test_transformer(T, X_test, y_test, device)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "ConfusionMatrixDisplay(cm).plot()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ml-0451",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
