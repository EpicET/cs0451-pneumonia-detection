{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import kagglehub\n",
    "\n",
    "# Download chest x-ray (will take a minute or two)\n",
    "data_path = kagglehub.dataset_download(\"paultimothymooney/chest-xray-pneumonia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = data_path + \"/chest_xray/train\"\n",
    "test_path = data_path + \"/chest_xray/test\"\n",
    "val_path = data_path + \"/chest_xray/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "331654a6",
    "outputId": "38b0ed3d-aa77-4638-f1ab-134e4db06634"
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(), #compression 3 rgb matrix into one for runtime\n",
    "    transforms.Resize((224, 224)), # can downsample here for runtime\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "#Loading train, test, and validation datasets.\n",
    "train_dataset = datasets.ImageFolder(train_path, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(test_path, transform=transform)\n",
    "val_dataset = datasets.ImageFolder(val_path, transform = transform)\n",
    "\n",
    "#dataloaders w 32 images each for batches (randomized)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(train_dataset.classes) # classes for the data (train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 839
    },
    "id": "b4cf45a4",
    "outputId": "412a7965-1b3c-4bd8-8398-a6fc7831eb15"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#image batch\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter) #image, label pair\n",
    "\n",
    "\n",
    "img_ten = images[0] #getting the 0th image/label pair\n",
    "label = labels[0]\n",
    "\n",
    "#tensor to NumPy (tensors no work for plotting :P)\n",
    "img_np = img_ten.numpy()\n",
    "img_np = np.transpose(img_np, (1, 2, 0))  #NOTE that the height/width need to be reordered when converting\n",
    "\n",
    "#Image plot with the label on the top (thanks Chodrow!!!)\n",
    "plt.imshow(img_np, cmap='gray')\n",
    "plt.title(f\"Label: {train_dataset.classes[label]}\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "i=10\n",
    "pnu_img_ten = images[i]\n",
    "\n",
    "pnu_label = labels[i]\n",
    "\n",
    "pnu_img_np = pnu_img_ten.numpy()\n",
    "pnu_img_np = np.transpose(pnu_img_np, (1, 2, 0))\n",
    "\n",
    "plt.imshow(pnu_img_np, cmap='gray')\n",
    "plt.title(f\"Label: {train_dataset.classes[pnu_label]}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "41b5c012",
    "outputId": "8b5fbb95-dd01-4e5a-dee1-f13f40fa9b52"
   },
   "outputs": [],
   "source": [
    "#Image Dimension (for later)\n",
    "pnu_img_ten.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Pneumonia Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "id": "5a9f3f48"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from PneumoniaAutoencoder import PneumoniaAutoencoder\n",
    "\n",
    "# Instantiate model, loss, optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") #easy to switch between cpu and gpu\n",
    "model = PneumoniaAutoencoder().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### Autoencoder training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "id": "6eaf897c"
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # progress bar (really nice)\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "\n",
    "    for images, _ in pbar:\n",
    "        images = images.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, images)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Update bar\n",
    "        pbar.set_postfix({'loss': loss.item()})\n",
    "\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Avg Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "id": "30ca87fa",
    "outputId": "2e58bb7b-8946-4f25-99b9-9e6cf968f359"
   },
   "outputs": [],
   "source": [
    "## reconstructed images\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# eval\n",
    "model.eval()\n",
    "\n",
    "# batch\n",
    "dataiter = iter(train_loader)\n",
    "images, _ = next(dataiter)\n",
    "images = images.to(device)\n",
    "\n",
    "# Reconstruct images\n",
    "with torch.no_grad():\n",
    "    reconstructions = model(images)\n",
    "\n",
    "# Move tensors to CPU for plotting (np can't use gpu)\n",
    "images = images.cpu()\n",
    "reconstructions = reconstructions.cpu()\n",
    "\n",
    "#transpose for tensor --> numpy\n",
    "def tensor_to_img(t):\n",
    "    t = t.numpy()\n",
    "    t = np.transpose(t, (1, 2, 0))\n",
    "    return t\n",
    "\n",
    "# Plot original and reconstructed\n",
    "n = 6 #num images\n",
    "plt.figure(figsize=(12, 4))\n",
    "for i in range(n):\n",
    "    # Original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(tensor_to_img(images[i]))\n",
    "    ax.set_title(\"Original\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # Reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(tensor_to_img(reconstructions[i]))\n",
    "    ax.set_title(\"Reconstructed\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {
    "id": "Kgu3lNNhf7zY"
   },
   "source": [
    "### Autoencoder PCA plot \n",
    "This to check if differences encoded are meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "id": "7EKgKYMRgAfI"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "latent_vectors = []\n",
    "labels_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_loader:  # labels: 0=norm, 1=pneu\n",
    "        images = images.to(device)\n",
    "        encoded = model.encoder(images)\n",
    "        # Flatten\n",
    "        encoded = encoded.view(encoded.size(0), -1).cpu().numpy()\n",
    "        latent_vectors.append(encoded)\n",
    "        labels_list.append(labels.cpu().numpy())\n",
    "\n",
    "# Stack into arrays\n",
    "import numpy as np\n",
    "X = np.vstack(latent_vectors)\n",
    "y = np.hstack(labels_list)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2) #2 Principal components\n",
    "X_pca = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "NQf4jg74gbf5",
    "outputId": "ab82f484-83f1-4b01-c222-cc2b9d992605"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_pca[y==0, 0], X_pca[y==0, 1], label=\"Normal\", alpha=0.5)\n",
    "plt.scatter(X_pca[y==1, 0], X_pca[y==1, 1], label=\"Pneumonia\", alpha=0.5)\n",
    "plt.title(\"PCA of Autoencoder Latent Space\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {
    "id": "2NsVqfq_uTok"
   },
   "source": [
    "## Contrastive Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def supervised_contrastive_loss(embeddings, labels: torch.Tensor, temperature=0.1):\n",
    "    #contrastive loss function for VAE\n",
    "\n",
    "        device = embeddings.device\n",
    "        labels = labels.contiguous().view(-1, 1)\n",
    "        mask = torch.eq(labels, labels.T).float().to(device)\n",
    "\n",
    "        dot_product = (embeddings @ embeddings.T) / temperature\n",
    "        logits_max, _ = torch.max(dot_product, dim=1, keepdim=True)\n",
    "        logits = dot_product - logits_max.detach()\n",
    "\n",
    "        exp_logits = torch.exp(logits) * (1 - torch.eye(len(labels), device=device))\n",
    "        log_prob = logits - torch.log(exp_logits.sum(1, keepdim=True) + 1e-8)\n",
    "\n",
    "        mean_log_prob_pos = (mask * log_prob).sum(1) / mask.sum(1)\n",
    "        loss = -mean_log_prob_pos.mean()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "id": "PsgGSOsBuTO5"
   },
   "outputs": [],
   "source": [
    "from ContrastiveEncoder import ContrastiveEncoder\n",
    "\n",
    "def train_encoder(model, dataloader, optimizer, device, epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for x, y in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            mu = model(x)\n",
    "            loss = supervised_contrastive_loss(mu, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1} - Contrastive Loss: {total_loss / len(dataloader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "id": "dwJO6Zugx3xD"
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "def plot_latent_space_3d(model, dataloader, device):\n",
    "    model.eval()\n",
    "    mus = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x = x.to(device)\n",
    "            mu = model(x)\n",
    "            mus.append(mu.cpu().numpy())\n",
    "            labels.append(y.numpy())\n",
    "\n",
    "    mus = np.concatenate(mus, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "\n",
    "    # PCA\n",
    "    pca = PCA(n_components=3)\n",
    "    reduced = pca.fit_transform(mus)\n",
    "\n",
    "    # pd.data.frame for plotly!\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame({\n",
    "        'PC1': reduced[:, 0],\n",
    "        'PC2': reduced[:, 1],\n",
    "        'PC3': reduced[:, 2],\n",
    "        'Label': labels\n",
    "    })\n",
    "\n",
    "    fig = px.scatter_3d(df, x='PC1', y='PC2', z='PC3',\n",
    "                        color=df['Label'].astype(str),\n",
    "                        title='3D PCA of Latent Space',\n",
    "                        labels={'color': 'Class'},\n",
    "                        opacity=0.7)\n",
    "    fig.update_traces(marker=dict(size=4))\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### Training Contrastive Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TEiMFnDRukP-",
    "outputId": "ae28df90-263a-496f-af56-ccc5204d7b5e"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ContrastiveEncoder(latent_dim=64).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "train_encoder(\n",
    "    model,\n",
    "    train_loader,\n",
    "    optimizer,\n",
    "    device,\n",
    "    epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "iUvZRxSfu4gf",
    "outputId": "6cbd8ae0-e848-4409-a07c-9107b75c478a"
   },
   "outputs": [],
   "source": [
    "plot_latent_space_3d(model, train_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {
    "id": "24107b28"
   },
   "source": [
    "## Variational AutoEncoder with Contrastive loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "id": "wN0t56_MmDA2"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from ContrastiveVAE import ContrastiveVAE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "id": "uUKDk7e_mKhc"
   },
   "outputs": [],
   "source": [
    "def train_vae(model: ContrastiveVAE, dataloader, optimizer, device, epochs=10, beta=1.0, contrastive_weight=1.0):\n",
    "    model.train()\n",
    "    recon_loss_fn = nn.MSELoss(reduction='sum')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for x, y in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            x_recon, mu, logvar = model(x)\n",
    "            recon_loss = recon_loss_fn(x_recon, x) / x.size(0)\n",
    "\n",
    "            kl_loss = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "            contrastive = supervised_contrastive_loss(mu, y)\n",
    "\n",
    "            loss = recon_loss + beta * kl_loss + contrastive_weight * contrastive\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1} - Loss: {total_loss / len(dataloader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "id": "pUhARMIImOho"
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "def plot_latent_space_3d(model, dataloader, device):\n",
    "    model.eval()\n",
    "    mus = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x = x.to(device)\n",
    "            mu, _ = model.encode(x)\n",
    "            mus.append(mu.cpu().numpy())\n",
    "            labels.append(y.numpy())\n",
    "\n",
    "    mus = np.concatenate(mus, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "\n",
    "    # PCA for visualization\n",
    "    pca = PCA(n_components=3)\n",
    "    reduced = pca.fit_transform(mus)\n",
    "\n",
    "    # Create pd.data.frame for Plotly\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame({\n",
    "        'PC1': reduced[:, 0],\n",
    "        'PC2': reduced[:, 1],\n",
    "        'PC3': reduced[:, 2],\n",
    "        'Label': labels\n",
    "    })\n",
    "\n",
    "    fig = px.scatter_3d(df, x='PC1', y='PC2', z='PC3',\n",
    "                        color=df['Label'].astype(str),\n",
    "                        title='3D PCA of Latent Space',\n",
    "                        labels={'color': 'Class'},\n",
    "                        opacity=0.7)\n",
    "    fig.update_traces(marker=dict(size=4))\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZPDhBdu_npUm",
    "outputId": "ca573de4-a8e7-4a65-c3e2-bed4ded30c98"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ContrastiveVAE(latent_dim=64).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "train_vae(\n",
    "    model,\n",
    "    train_loader,\n",
    "    optimizer,\n",
    "    device,\n",
    "    epochs=10,\n",
    "    beta=1.0,\n",
    "    contrastive_weight=5 # 5 ~208, 10 ~ 229\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "ftBBzBFtnwFC",
    "outputId": "d417e270-0958-4c60-8e91-82f53a3cfae0"
   },
   "outputs": [],
   "source": [
    "plot_latent_space_3d(model, train_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {
    "id": "5NxGpe-B0JVU"
   },
   "source": [
    "## Testing on Model to see how well it performs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "id": "GPr0eXZG0EEQ"
   },
   "outputs": [],
   "source": [
    "def extract_latent_vectors(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_mu = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x = x.to(device)\n",
    "            mu, _ = model.encode(x)\n",
    "            all_mu.append(mu.cpu().numpy()) #add all into np array\n",
    "            all_labels.append(y.numpy())\n",
    "\n",
    "    X = np.concatenate(all_mu, axis=0)\n",
    "    y = np.concatenate(all_labels, axis=0)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "id": "2RMWwU-s0Hpq"
   },
   "outputs": [],
   "source": [
    "X_train, y_train = extract_latent_vectors(model, train_loader, device)\n",
    "X_test, y_test = extract_latent_vectors(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1beGZ0CQ0SH1",
    "outputId": "4adfbdd2-4433-426b-9bf3-b8fae6718b9e"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "model_test = LogisticRegression(max_iter=100, verbose = 1)\n",
    "model_test.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model_test.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "NhxPfS8K0Wjz",
    "outputId": "4328e0a4-458a-4dbf-fdc4-1224d3f7f93c"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(model_test, X_test, y_test)\n",
    "plt.title(\"Confusion Matrix for Logistic Regression\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ml-0451",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
